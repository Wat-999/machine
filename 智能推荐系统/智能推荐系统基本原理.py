#智能推荐系统属于非监督式学习，是机器学习一个非常重要的应用领域，它能带来的经济价值往往是直接且非常可观的。
#智能推荐系统的应用场景：互联网每天都在产生海量信息，用户行为数据呈现爆发式增长。用户会有直接和明确的需求
#但也可能是在漫无目的地搜寻。智能推荐系统可以通过分析用户的浏览次数、浏览时间、点击率等指标，挖掘出用户感兴趣的内容或商品，然后进行个性化推荐。
#如果推荐的内容能高效匹配用户的需求，就能优化用户体验，提高用户黏性，创造额外收入。
#智能推荐系统的应用场景极为广泛，例如：当用户看过电影蜘蛛侠后，豆瓣电影可能会推荐同为漫威系列的钢铁侠，当用户收藏单曲致爱丽丝后，网易云音乐可能会推荐同为古典音乐的梦中婚礼

#智能推荐系统的基础：协同过滤算法
#搭建智能推荐系统的算法有很多，商业实战中用得较多的是协同过滤算法。协同过滤算法的原理是根据用户群体的产品偏好数据，发现用户或物品之间的相关性
#并基于这些相关性和基于物品的协同过滤算法
#1基于用户的协同过滤算法
#基于用户的协同过滤算法的本质是寻找相似的用户：通过一个用户的相关数据寻找与该用户相似的其他用户，进而为该用户推荐相似用户关注的产品
#如下表表示，用户1和用户2都给商品A、B、C打了高分，那么可以将用户1和用户2划分在同一个用户群体，此时若用户2还给商品D打了高分，那么就可以将商品D推荐给用户1
#       商品A     商品B     商品C     商品D
#用户1    10        10        9       ？
#用户2    10         9        10      10
#用户3    3          2        4       6

#2基于物品的协同过滤算法
#基于物品的协同过滤算法的本质是寻找相似的物品：通过一个物品的相关数据寻找与该物品相似的其他物品，进而为关注该物品的用户推荐相似的物品
#如下表所示，图书A和图书B都被用户1、2、3购买过(1表示购买，0表示未购买），那么可以认为图书A和图书B具有较强的相似度，进而推测喜欢图书A的用户
#同样也会喜欢图书B。当用户4购买图书B时，根据图书A和图书B的相似性，可以将图书A推荐给用户4。
#       用户1      用户2     用户3    用户4
#图书A    1         1          1       ？
#图书B    1         1          1       1
#图书C    1         0          0       1
#在商业实战中，大多数应用场景偏向于使用基于物品的协同过滤算法，主要原因如下：
#通常情况下，用户的数量是非常庞大的(如淘宝的用户群体达数亿），而物品的数量则相对有限，因此计算不同物品的相似度往往比计算不同用户的相似度容易很多
#用户的喜好较为多变，而物品的属性较明确，不随时间变化，过去的用户对物品的评分长期有效，所以物品的相似度比较固定
#可以预先离线计算好物品相似度，把结果存在表中，需要向用户推荐时再从表中调用。

#计算相似度常用的方法
#无论是基于用户还是基于产品的协同过滤算法，其本质都是寻找数据之间的相似度。计算相似度有3种常用方法：欧式距离、余弦值、皮尔逊相关系数
# # 第十四章 智能推荐系统 - 协同过滤算法
# # 14.2 相似度计算三种常见方法
# 14.2.1 欧式距离
import pandas as pd
df = pd.DataFrame([[5, 1, 5], [4, 2, 2], [4, 2, 1]], columns=['用户1', '用户2', '用户3'], index=['物品A', '物品B', '物品C'])
print(df)
#欧式距离公式：d(A,B)=√(X1-Y1)^2+(X2-Y2)^2+(X3-Y3)    计算物品A和物品B之间的欧式距离
#欧式距离相似度sim(A,B)。由公式可知，两物品之间的欧式距离越小，则相似度越大，两物品越相近  ：sim(A,B)=1/1+d(A,B)

import numpy as np
dist = np.linalg.norm(df.iloc[0] - df.iloc[1])
print(dist)

# # 14.2.2 余弦内置函数
import pandas as pd
df = pd.DataFrame([[5, 1, 5], [4, 2, 2], [4, 2, 1]], columns=['用户1', '用户2', '用户3'], index=['物品A', '物品B', '物品C'])
print(df)
#在n维向量空间中若向量a=(X1,X2,X3,~~~~Xn),向量b(Y1,Y2,Y3~~~~~Yn),则向量a和向量b的夹角余弦值=X1Y1+X2Y2+X3Y3+~~~~~XnYn/√X1^2+X2^2+~~~Xn^2 +√Y1^2+Y2^2=Y3^2+~~~~Yn^2
#余弦相似度越大，则物品之间越相似
from sklearn.metrics.pairwise import cosine_similarity
user_similarity = cosine_similarity(df)
pd.DataFrame(user_similarity, columns=['物品A', '物品B', '物品C'], index=['物品A', '物品B', '物品C'])

# # 14.2.3 皮尔逊相关系数简单版  皮尔逊相关系数取值范围[-1, 1]
from scipy.stats import pearsonr
X = [1, 3, 5, 7, 9]
Y = [9, 8, 6, 4, 2]
corr = pearsonr(X, Y)
#只需给pearsonr（）函数传入两个数组，它就能返回一个元组，其中包含两个浮点数，皮尔逊相关系数r值和显著水平p值。
#p值与显著性检验有关，p<0.05表示显著相关，即两个变量之间的相关性真的存在，而不是偶然因素引起的。
#只有在显著性相关的前提下，r值才有意义。简单来说就是先通过观察p值判定是否真的存在相关性，再根据r值判定相关性有多强
print('相关系数r值为' + str(corr[0]) + '，显著性水平P值为' + str(corr[1]))

import pandas as pd
df = pd.DataFrame([[5, 4, 4], [1, 2, 2], [5, 2, 1]], columns=['物品A', '物品B', '物品C'], index=['用户1', '用户2', '用户3'])
print(df)

A = df['物品A']
corr_A = df.corrwith(A)
print(corr_A)

print(df.corr())




