#建立模型分析特征数据时，很可能会面临特征数据维度过大的问题。例如，根据已有的信用卡持有人信息及其违约数据来建立信用卡违约预测模型时，
#数据可能包含申请人的收入、年龄、性别、婚姻状况、工作单位等数百个维度地特征。如果将所有特征数据用来拟合模型，
#会提高模型的复杂度，造成过拟合风险显著增大，且不同的特征数据间可能存在共线性，此时就需要对数据进行降维，以浓缩特征向量。

#数据降维
#如果特征变量对数量非常多(如成百上千个特征变量），我们往往需要进行数据降维，降维的方法主要有选择特征和抽取特征两种：
#选择特征是从原有的特征中挑选出最佳的特征；抽取特征则是将数据由高维向低维投影，进行坐标的线性转换。
#PCA即为典型的抽取特征的方法，它不仅是对高维数据进行降维，更重要的是经过降维去除噪声，发现数据中的模式。
#二维空间降维就是把二维降成一维，在实际进行数据降维前，需要先对特征数据做零均值化处理，即将每一个特征维度对数据减去该特征的均值
#例如，此处的二维数据(1,1),(2,2),(3,3),其特征x(1,2,3)和特征y(1,2,3)的均值都是(1+2+3)/3=2，
#每个特征都减去均值后，数据被转化为(-1,-1),(0,0),(1,1)。再对零均值化后的数据进行线性组合，
#二维空间中的3个点就被依次转化为数轴上的-√2、0、√2
#总结来说，二维到一维的数据降维的本质就是将原始数据做零均值化处理后，寻找合适的线性组合系数α和β，将二维数据转换一维数据：X=αx+βx

#2 n维空间降维
#如果原特征变量有n个，那么就是n维空间降维。n维空间降维的思路和二维空间降维的思路是一致的，都是寻找合适的线性组合系数。
#例如，将n维数据（X1,x2~~~~~~~Xn)转换为一维数据，就是寻找线性组合系数a1，a2～～～an   F = a1X1+a2X2+~~~~~anXn

#二维空间降维
import numpy as np
X = np.array([[1, 1], [2, 2], [3, 3]])
print(X)

#搭建PCA模型进行降维
from sklearn.decomposition import PCA    #引入PCA模型
pca = PCA(n_components=1)      #设置参数n_components=1，即保留的成分个数，这里设置为1，也就是将二维数据降为一维数据
#n_components参数不仅可以设置降维后成分个数，还可以设置降维后保留的信息百分比，例如将其设置0.9就是在降维后保留原特征的90%的信息
#需要注意的是，如果将n_components参数设置降维后成分的个数，其值不能大于min(n_samples, n_features),即样本数和特征变量数两者之中的最小数
pca.fit(X)    #进行模型训练
X_transformed = pca.transform(X)  #对原始数据进行降维并将结果赋值
print(X_transformed)
#结果解读：虽然变量X_transformed的数据格式仍然是二维数组，但其只有一列，实质上是一个一维数组，与之前手动计算的结果是一致的，这样PCA降维就完成了
print(pca.components_)   #获取线性组合系数，打印的两个数其实就是变量X和变量Y前面的系数1/√2
#注意：pca.components_是一个二维数据，所以要通过两层索引来获取其中的元素，且因为元素是数字，所以在进行字符串拼接时需要先用str（）函数进行转换
a = pca.components_[0][0]
b = pca.components_[0][1]
print(str(a) + ' * X' + str(b) + ' * Y')



#三维空间降维
import pandas as pd
X = pd.DataFrame([[45, 0.8, 9120], [40, 0.12, 2600], [38, 0.09, 3042], [30, 0.04, 3300],
                  [39, 0.21, 3500]],columns=['年龄（岁）', '负债比率', '月收入（元）'])
print(X)
#可以看到，3个维度的特征数据的量级别相差较大。如果数据中某一特征的数值很大，那么它在计算中所占的比重就会很大，pca降维时会更看重这个特征
#而忽略其他数值小的特征。因此，先对三个维度的数据进行标准化，有利于pca降维时梯度下降法的收敛
from sklearn.preprocessing import StandardScaler
X_new = StandardScaler().fit_transform(X)   #这离采用的是Z-score标准化
print(X_new)
#结果解读：第一列对应标准化后的特征维度X，第二列对应标准化后的特征维度Y，第3列对应标准化后的特征维度Z

#搭建PCA模型进行降维
from sklearn.decomposition import PCA
pca = PCA(n_components=2)    #设置参数n_components=2，即保留的成分个数，这里设置为2，也就是将三维数据降为二维数据
pca.fit(X_new)   #对标准化后的数据进行模型训练
X_tranformed = pca.transform(X_new)     #transform()函数对标准化后的数据进行降维
print(X_tranformed)
#结果解读可以看到此时的变量X_tranformed是一个二维数组

print(pca.components_)    #获取线性组合系数
#可以看到pca.components_是一个二维数组，第一个元素中的3个数对应的是下述公式中的系数a11，a12，a13，，
#第二个元素中的3个数对应的是下述公式中的系数a21，a22，a23
#F1 =a11X1+a12X2+a13X3   F2 =a21X1+a22X2+a23X3


#打印降维过程中原始的线性组合公式
dim = ['年龄（岁）', '负债比率', '月收入（元）']    #存储变量的名称
for i in pca.components_:                      #通过 for循环遍历系数二维组，其中i代表系数列表[a11,a12,a13]和[a21,a22,a23]
    formula = []                               #创建空列表
    for j in range(len(i)):                    #遍历系数列表中每一个系数，如第一个系数列表中a11,a12,a13
        formula.append(str(i[j]) + ' * ' + dim[j])
        # 通过字符串拼接的方法拼接系数、乘号、和特征变量名称，并用append（）函数添加到formula列表中，注意：系数是数字，所以需要用str（）函数进行转换
    print(" + ".join(formula))     #用join（）函数将列表转换成字符串，并用+号连接里面的列表里的元素
    #print(formula)